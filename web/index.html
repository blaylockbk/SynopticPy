<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title></title>
    <meta name="description" content="" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="https://pyscript.net/alpha/pyscript.css" />
    <script defer src="https://pyscript.net/alpha/pyscript.js"></script>
    <py-env>
        - matplotlib
        - pandas
        - requests
        - numpy
    </py-env>
  </head>
  <body>
    <div id="matplotlib-lineplot"></div>
    <h1>PyScript - HTTP Requests pyfetch</h1>
    <div id="request_output"></div>
    <py-script output="matplotlib-lineplot">
#import requests
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pyodide.http import pyfetch  # Use instead of requests
import asyncio

# Change default date formatter
plt.rcParams['date.autoformatter.day'] = '%b %d\n%H:%M'
plt.rcParams['date.autoformatter.hour'] = '%b %d\n%H:%M'

config = {
    'default': {'verbose': True,
    'hide_token': True,
    'rename_value_1': True,
    'rename_set_1': True,
    'token': '0bbe0e9fda7945a68951cc1bdebb2b0d'}
}

# Available API Services
# https://developers.synopticdata.com/mesonet/v2/
_service = {"auth", "networks", "networktypes", "variables", "qctypes"}
_stations = {"metadata", "timeseries", "precipitation", "nearesttime", "latest"}
_service.update(_stations)

# Station Selector Parameters Set
_stn_selector = {
    "stid",
    "country",
    "state",
    "country",
    "status",
    "nwszone",
    "nwsfirezone",
    "cwa",
    "gacc",
    "subgacc",
    "vars",
    "varsoperator",
    "network",
    "radius",
    "limit",
    "bbox",
    "fields",
}

# Rename "set_1" and "value_1" names is a convience I prefer.
## You can turn these off in your requests by setting `rename_set_1`
## and `rename_value_1` to False in your function call where applicable.
def _rename_set_1(df):
    """
    Rename Variable Columns Names

    Remove the 'set_1' and 'set_1d' from column names
    Sets 2+ will retain their full names.
    The user should refer to SENSOR_VARIABLES to see which
    variables are derived

    """

    ## Get list of current column names
    dummy_columns = list(df.columns)

    # Remove '_set_1' and '_set_1d' from column name
    var_names = [
        "_".join(v.split("_")[:-2]) if "_set_1" in v else v for v in dummy_columns
    ]

    # Number of observations in each column
    obs_count = list(df.count())

    # Sometimes, set_1 and set_1d are both returned. In that
    # case, we need to determin which column has the most
    # observations and use that as the main variable. The set
    # with fewer data will retain the 'set_1' or 'set_1d' label.
    renames = {}
    for i, name in enumerate(var_names):
        # Determine all indices this variable type is located
        var_bool = [v.startswith(name + "_set_1") for v in dummy_columns]
        var_idx = np.where(var_bool)[0]

        if len(var_idx) == 1:
            # This variable is only listed once. Rename with var_name
            renames[dummy_columns[i]] = var_names[var_idx[0]]
        elif len(var_idx) > 1:
            # This variable is listed more than once.
            # Determine which set has the most non-NaN data and
            # rename that column as var_name.
            max_idx = var_idx[np.argmax([obs_count[i] for i in var_idx])]
            if max_idx == i:
                # If the current iteration matches the var_idx with
                # the most data, rename the column without set number.
                renames[dummy_columns[i]] = var_names[max_idx]
            else:
                # If the current iteration does not match the var_idx
                # with the most data, then retain the original column
                # name with the set number.
                renames[dummy_columns[i]] = dummy_columns[i]
        else:
            # This case should only occur during my testing.
            renames[dummy_columns[i]] = dummy_columns[i]
    df.rename(columns=renames, inplace=True)
    df.attrs["RENAMED"] = renames
    return df


print("Hello, World!")

#web = synoptic_api("timeseries", verbose=True, stid="UKBKB", recent="200M")
#data = web.json()
#print(data)

from pyodide.http import pyfetch
import asyncio
stid="UKBKB,KMRY"
vars="air_temp"
units="english"
recent="300"
token="0bbe0e9fda7945a68951cc1bdebb2b0d"
URL = f"https://api.synopticdata.com/v2/stations/timeseries?recent={recent}&stid={stid}&vars={vars}&units={units}&token={token}"
response = await pyfetch(url=URL, method="GET")
status = response.status
data = await response.json()


output = f"<h1>GET request=> </h1><br>status:{status}<br>json:{data}"

pyscript.write('request_output', output)

rename_set_1 = True

# Build a separate pandas.DataFrame for each station.
Z = []
for stn in data["STATION"]:
    obs = stn.pop("OBSERVATIONS")
    senvars = stn.pop("SENSOR_VARIABLES")

    # Turn Data into a DataFrame
    df = pd.DataFrame(obs).set_index("date_time")

    # Remaining data in dict will be returned as attribute
    df.attrs = stn

    # Convert datetime index string to datetime
    df.index = pd.to_datetime(df.index)

    # Sort Column order alphabetically
    df = df.reindex(columns=df.columns.sort_values())

    # Break wind into U and V components, if speed and direction are available
    if all(["wind_speed" in senvars, "wind_direction" in senvars]):
        for i_spd, i_dir in zip(
            senvars["wind_speed"].keys(), senvars["wind_direction"].keys()
        ):
            u, v = spddir_to_uv(obs[i_spd], obs[i_dir])
            this_set = "_".join(i_spd.split("_")[-2:])
            df[f"wind_u_{this_set}"] = u
            df[f"wind_v_{this_set}"] = v
            data["UNITS"]["wind_u"] = data["UNITS"]["wind_speed"]
            data["UNITS"]["wind_v"] = data["UNITS"]["wind_speed"]

    if rename_set_1:
        df = _rename_set_1(df)

    # Drop Row if all data is NaN/None
    df.dropna(how="all", inplace=True)

    # In the DataFrame attributes, Convert some strings to float/int
    # (i.e., ELEVATION, latitude, longitude) BUT NOT STID!
    for k, v in df.attrs.items():
        if isinstance(v, str) and k not in ["STID"]:
            try:
                n = float(v)
                if n.is_integer():
                    df.attrs[k] = int(n)
                else:
                    df.attrs[k] = n
            except:
                pass

    if len(df.columns) != len(set(df.columns)):
        warnings.warn("ü§πüèº‚Äç‚ôÇÔ∏è DataFrame contains duplicate column names.")

    # Rename lat/lon to lowercase to match CF convenctions
    df.attrs["latitude"] = df.attrs.pop("LATITUDE")
    df.attrs["longitude"] = df.attrs.pop("LONGITUDE")

    # Include other info
    for i in data.keys():
        if i != "STATION":
            df.attrs[i] = data[i]
    df.attrs["SENSOR_VARIABLES"] = senvars
    #df.attrs["params"] = params
    df.attrs["service"] = "stations_timeseries"

    Z.append(df)

df1, df2 = Z


fig, ax = plt.subplots(figsize=[10,6])
for df in Z:
    plt.plot(df.index, df.air_temp, marker='o', markersize=3, linestyle='-', label=df.attrs['STID'])
plt.ylabel('Temperature (F)')
plt.title('Air Temperature')
plt.legend()
plt.grid(alpha=.2)
plt.tight_layout()
fig
     </py-script>


</body>
</html>
